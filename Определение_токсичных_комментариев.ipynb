{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Определение токсичных комментариев.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmazurov/ML-model-for-a-metalworking-enterprise/blob/main/%D0%9E%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D1%82%D0%BE%D0%BA%D1%81%D0%B8%D1%87%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%80%D0%B8%D0%B5%D0%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4e6xvJ4ab02"
      },
      "source": [
        "# Проект для «Викишоп»\n",
        "\n",
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Задача: \n",
        "Обучить модель классифицировать комментарии на позитивные и негативные, основываясь на наборе данных с разметкой о токсичности правок.\n",
        "\n",
        "Основная метрики качества *F1* должна быть не меньше 0.75. \n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true,
        "id": "3gWuR3EVab09"
      },
      "source": [
        "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
        "</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Подготовка\" data-toc-modified-id=\"1.-Подготовка-1.1\">1. Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.1.1\">Вывод</a></span></li></ul></li><li><span><a href=\"#2.-Обучение\" data-toc-modified-id=\"2.-Обучение-1.2\">2. Обучение</a></span></li><li><span><a href=\"#3.-Выводы\" data-toc-modified-id=\"3.-Выводы-1.3\">3. Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-1.4\">Чек-лист проверки</a></span></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqyXzgWrab0-"
      },
      "source": [
        "## 1. Подготовка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xgFSdrRab0_",
        "outputId": "1e4a2ac5-82d1-4ed0-b1c1-3563c6f79d34"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi9wpomrab1A"
      },
      "source": [
        "data = pd.read_csv('/datasets/toxic_comments.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRyeuWmrab1B",
        "outputId": "7151f3dc-c4d2-4046-898d-c1c111f31996"
      },
      "source": [
        "display(data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpYqE8U7ab1B",
        "outputId": "e2f52e1c-875d-4f16-8c8f-4c3037fc0c56"
      },
      "source": [
        "display(data.isnull().sum())\n",
        "display(data.duplicated().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "text     0\n",
              "toxic    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xyuEbgOab1C",
        "outputId": "61494254-7cf7-44e9-f38c-912a3fc55a85"
      },
      "source": [
        "data['toxic'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    143346\n",
              "1     16225\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cd29R_oab1C"
      },
      "source": [
        "### Вывод\n",
        "\n",
        "- В данных нет пропущенных значений или дубликатов \n",
        "- Примерное соотношение токсичных комментариев к обычным 9:1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-zwr1Pjab1D"
      },
      "source": [
        "**Для работы над задачей проведем лемматизацию, очистим от стоп-слов**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FM2cZPkab1D"
      },
      "source": [
        "data['lemm_text'] = data['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIy65Mt5ab1E"
      },
      "source": [
        "# Очистка текста\n",
        "\n",
        "def clean_text(row):\n",
        "    row = re.sub(r\"(?:\\n|\\r)\", \" \", row)\n",
        "    row = re.sub(r\"[^a-zA-Z ]+\", \"\", row).strip()\n",
        "    row = row.lower()\n",
        "    \n",
        "    return row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47wMpTUbab1E",
        "outputId": "1c89cdba-1783-4b00-fc33-85ee1704db7e"
      },
      "source": [
        "data['lemm_text'] = data['lemm_text'].apply(clean_text)\n",
        "\n",
        "display(data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemm_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>more i cant make any real suggestions on impro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic  \\\n",
              "0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  D'aww! He matches this background colour I'm s...      0   \n",
              "2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                           lemm_text  \n",
              "0  explanation why the edits made under my userna...  \n",
              "1  daww he matches this background colour im seem...  \n",
              "2  hey man im really not trying to edit war its j...  \n",
              "3  more i cant make any real suggestions on impro...  \n",
              "4  you sir are my hero any chance you remember wh...  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhxBY2AGab1E"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(text):\n",
        "    word_list = nltk.word_tokenize(text)\n",
        "    llemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "        \n",
        "    return llemmatized_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnl89bf5ab1F",
        "outputId": "8d4f6825-810d-49f7-f5fe-d62bffd5bf55"
      },
      "source": [
        "data['lemm_text'] = data['lemm_text'].apply(lemmatize)\n",
        "\n",
        "display(data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>lemm_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>daww he match this background colour im seemin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man im really not trying to edit war it ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>more i cant make any real suggestion on improv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic  \\\n",
              "0  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  D'aww! He matches this background colour I'm s...      0   \n",
              "2  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "                                           lemm_text  \n",
              "0  explanation why the edits made under my userna...  \n",
              "1  daww he match this background colour im seemin...  \n",
              "2  hey man im really not trying to edit war it ju...  \n",
              "3  more i cant make any real suggestion on improv...  \n",
              "4  you sir are my hero any chance you remember wh...  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrwEyH_Vab1F"
      },
      "source": [
        "**TF IDF без стоп-слов**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4YuiU24ab1G"
      },
      "source": [
        "# Для удобства дальнейшей работы удалим столбец с исходным текстом\n",
        "\n",
        "data = data.drop(['text'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQsCu7fGab1G"
      },
      "source": [
        "# Разделение датафрейма на обучающую и тестовую выборки\n",
        "\n",
        "features = data['lemm_text']\n",
        "target = data['toxic']\n",
        "\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, stratify=target, \n",
        "                                                                            test_size=0.25)\n",
        "\n",
        "corpus_train = features_train.values.astype('U')\n",
        "corpus_test = features_test.values.astype('U')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDhYkyBfab1G",
        "outputId": "ae7e48eb-4a6e-4cc3-8817-2e109de62633"
      },
      "source": [
        "# Обработка стоп-слов\n",
        "\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
        "\n",
        "# Учим и трансформируем обучающую выборку\n",
        "features_train = count_tf_idf.fit_transform(corpus_train)\n",
        "\n",
        "print(\"Размер обучающей выборки tf_idf с учётом стоп-слов:\", features_train.shape)\n",
        "\n",
        "# Трансформируем тестовую выборку\n",
        "features_test = count_tf_idf.transform(corpus_test)\n",
        "\n",
        "print(\"Размер тестовой выборки tf_idf с учётом стоп-слов:\", features_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер обучающей выборки tf_idf с учётом стоп-слов: (119678, 175621)\n",
            "Размер тестовой выборки tf_idf с учётом стоп-слов: (39893, 175621)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRZVRkf1ab1G"
      },
      "source": [
        "## 2. Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-B8h4Z4ab1H"
      },
      "source": [
        "**Основной моделью для обучения выберем логистическую регрессию. Эта модель лучше всего подходит для работы с текстами. Для сравнения возьмем модель Случайного леса. В модели логистической регрессии поработаем с коэффициент регуляризации С.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt3j0h_jab1H"
      },
      "source": [
        "**Логистическая регрессия TF IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_xDdv75ab1H",
        "outputId": "af8c810a-0cf1-40b8-bd0b-05f23a63ce33"
      },
      "source": [
        "# Модель со стандартными гиперпараметрами\n",
        "\n",
        "model = LogisticRegression(random_state=12345)\n",
        "model.fit(features_train, target_train)\n",
        "predict = model.predict(features_test)\n",
        "print('Оценка F1 для модель логистической регрессии:', f1_score(target_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Оценка F1 для модель логистической регрессии: 0.7313052600029971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSInVpnaab1I",
        "outputId": "ba51f099-67f4-4391-b8e0-255bb95a868d"
      },
      "source": [
        "model = LogisticRegression(C=10, random_state=12345)\n",
        "model.fit(features_train, target_train)\n",
        "predict = model.predict(features_test)\n",
        "print('Оценка F1 для модель логистической регрессии:', f1_score(target_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка F1 для модель логистической регрессии: 0.7811419881100512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_DrpmRVab1I"
      },
      "source": [
        "**Случайный лес TF IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtaz4y5nab1I",
        "outputId": "e7a038d9-ebe1-4337-e4b6-18e5d9f98a8a"
      },
      "source": [
        "# Модель со стандартными гиперпараметрами\n",
        "\n",
        "model = RandomForestClassifier(random_state=12345)\n",
        "model.fit(features_train, target_train)\n",
        "predict = model.predict(features_test)\n",
        "\n",
        "print('Оценка F1 для модель случайного леса:', f1_score(target_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Оценка F1 для модель случайного леса: 0.6670842467898528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMhEVZz4ab1I",
        "outputId": "e49d3df3-0404-4291-f392-9a6ab06870cb"
      },
      "source": [
        "model = RandomForestClassifier(random_state=12345, n_estimators=500, max_leaf_nodes=3)\n",
        "model.fit(features_train, target_train)\n",
        "predict = model.predict(features_test)\n",
        "print(f1_score(target_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0f8bxSoab1J"
      },
      "source": [
        "**Логистическая регрессия Мешок слов**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Nt0Ivtab1J",
        "outputId": "8cf93cbb-fa24-4ab2-881a-502e0ea1f57c"
      },
      "source": [
        "# Обработка стоп-слов\n",
        "\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "count_vect = CountVectorizer(stop_words=stopwords)\n",
        "\n",
        "# Учим и трансформируем обучающую выборку\n",
        "features_train = count_vect.fit_transform(corpus_train)\n",
        "\n",
        "print(\"Размер обучающей выборки мешка слов с учётом стоп-слов:\", features_train.shape)\n",
        "\n",
        "# Трансформируем тестовую выборку\n",
        "features_test = count_vect.transform(corpus_test)\n",
        "\n",
        "print(\"Размер тестовой выборки мешка слов с учётом стоп-слов:\", features_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер обучающей выборки мешка слов с учётом стоп-слов: (119678, 175621)\n",
            "Размер тестовой выборки мешка слов с учётом стоп-слов: (39893, 175621)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9sMO7MZab1J",
        "outputId": "c9cfff89-4091-4360-c6cd-4a6046f4b90a"
      },
      "source": [
        "# Модель со стандартными гиперпараметрами\n",
        "\n",
        "model = LogisticRegression(random_state=12345)\n",
        "model.fit(features_train, target_train)\n",
        "predict = model.predict(features_test)\n",
        "print('Оценка F1 для модель логистической регрессии:', f1_score(target_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Оценка F1 для модель логистической регрессии: 0.7025972076264826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHXFXZVYab1K",
        "outputId": "262ebe38-9a5f-4849-9a26-d56961a2b275"
      },
      "source": [
        "model = LogisticRegression(C=10, random_state=12345)\n",
        "model.fit(features_train, target_train)\n",
        "predict = model.predict(features_test)\n",
        "print('Оценка F1 для модель логистической регрессии:', f1_score(target_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оценка F1 для модель логистической регрессии: 0.7059877557115125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3irPb7qab1K"
      },
      "source": [
        "**Случайный лес мешок слов**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyzVQG_Cab1K",
        "outputId": "817936fa-8a2a-4bfe-8206-8113d6ae22cb"
      },
      "source": [
        "# Модель со стандартными гиперпараметрами\n",
        "\n",
        "model = RandomForestClassifier(random_state=12345)\n",
        "model.fit(features_train, target_train)\n",
        "predict = model.predict(features_test)\n",
        "\n",
        "print('Оценка F1 для модель случайного леса:', f1_score(target_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Оценка F1 для модель случайного леса: 0.6687306501547987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1fylqIlab1L"
      },
      "source": [
        "## 3. Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp5eOItbab1L"
      },
      "source": [
        "1. Лучший результат показала модель логистической регрессии, с гиперпараметром С=10 и TF IDF\n",
        "2. Модель случайного леса показала результат только на гиперпараметрах по умолчанию\n",
        "3. Метод преобразования текстов TF IDF эфективнее, чем создание мешка слов\n",
        "4. Для эффективной предобработки текста необходима провести чистку, а после лемматизацию"
      ]
    }
  ]
}